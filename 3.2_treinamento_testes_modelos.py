# ğŸ“¥ Importando Bibliotecas
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from imblearn.over_sampling import SMOTE

# ğŸ“Œ 1ï¸âƒ£ Carregar base de dados jÃ¡ fusionada
print("ğŸ“‚ Carregando `base_fusionada.csv`...")
df = pd.read_csv("base_fusionada.csv", delimiter=";", encoding="utf-8")

print(f"âœ… Base carregada com {df.shape[0]} registros e {df.shape[1]} colunas.")

# ğŸ“Œ 2ï¸âƒ£ SeleÃ§Ã£o de variÃ¡veis
features = [
    "PRECIPITAÃ‡ÃƒO TOTAL, HORÃRIO (mm)",  
    "TEMPERATURA DO AR - BULBO SECO, HORARIA (Â°C)",  
    "UMIDADE RELATIVA DO AR, HORARIA (%)",  
    "VENTO, VELOCIDADE HORARIA (m/s)",  
    "valor_unitario"  
]
target = "qtd_atividade_bin"

# ğŸ—ï¸ 3ï¸âƒ£ Tratamento de valores ausentes (Preenchendo com a mÃ©dia)
print("ğŸ”„ Tratando valores ausentes...")

imputer = SimpleImputer(strategy="mean")  # Usa a mÃ©dia para preencher NaN
df[features] = imputer.fit_transform(df[features])  # Aplica a substituiÃ§Ã£o

# ğŸ“Œ 4ï¸âƒ£ Remover linhas onde `qtd_atividade_bin` estÃ¡ ausente
df = df.dropna(subset=[target])
print(f"âœ… ApÃ³s limpeza, restam {df.shape[0]} registros.")

# âœ‚ï¸ 5ï¸âƒ£ SeparaÃ§Ã£o Treino/Teste
X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)

# ğŸ“Š 6ï¸âƒ£ AplicaÃ§Ã£o de SMOTE para balanceamento
print("ğŸ”„ Aplicando SMOTE para balanceamento da base...")
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

print(f"âœ… Base balanceada: {X_train_res.shape[0]} registros apÃ³s SMOTE.")

# ğŸ”„ 7ï¸âƒ£ NormalizaÃ§Ã£o dos dados
scaler = StandardScaler()
X_train_res = scaler.fit_transform(X_train_res)
X_test = scaler.transform(X_test)

# ğŸ“Œ 8ï¸âƒ£ DicionÃ¡rio de Modelos a testar
modelos = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric="logloss", random_state=42),
    "LightGBM": LGBMClassifier(random_state=42),
    "Redes Neurais": MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
}

# ğŸ¯ ğŸ”¬ 9ï¸âƒ£ Treinamento e AvaliaÃ§Ã£o dos Modelos
resultados = {}

print("\nğŸ”¬ Testando Modelos de Machine Learning...\n")
for nome, modelo in modelos.items():
    print(f"\nğŸš€ Treinando Modelo: {nome}")
    modelo.fit(X_train_res, y_train_res)
    y_pred = modelo.predict(X_test)
    
    acuracia = accuracy_score(y_test, y_pred)
    f1 = cross_val_score(modelo, X_train_res, y_train_res, cv=3, scoring='f1').mean()
    
    print(f"ğŸ“Š AcurÃ¡cia: {acuracia:.4f}")
    print(f"âš–ï¸ F1-Score: {f1:.4f}")
    print("\nğŸ“Š Matriz de ConfusÃ£o:")
    print(confusion_matrix(y_test, y_pred))
    
    resultados[nome] = {
        "AcurÃ¡cia": acuracia,
        "F1-Score": f1
    }

# ğŸ“Š ğŸ”„ ComparaÃ§Ã£o Final entre Modelos
resultados_df = pd.DataFrame(resultados).T
print("\nğŸ“Š ComparaÃ§Ã£o Final entre Modelos:")
print(resultados_df)

# ğŸ“ˆ ğŸ”„ GrÃ¡fico de ComparaÃ§Ã£o
plt.figure(figsize=(10, 5))
sns.barplot(x=resultados_df.index, y=resultados_df["F1-Score"], palette="viridis")
plt.title("ComparaÃ§Ã£o de Modelos - F1-Score")
plt.ylabel("F1-Score")
plt.xticks(rotation=45)
plt.show()
